{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Models of Mental Health Based on Social Media Generalize?\n",
    "\n",
    "Overview of code and some data. The best way to become familiar with the functionalities of this codebase is to look at source code for the `fit` and `predict` methods of the `MentalHealthClassifier`. Alternatively, examine the README.md in the root of this repository to understand how datasets were acquired, processed, explored, and modeled.\n",
    "\n",
    "Questions? Contact Keith Harrigian at kharrigian@jhu.edu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "\n",
    "We recommend running this code within a conda environment (python >= 3.6, no GPU required). Everything should mostly work out of the box by running `pip install -e .` in the root of this repository. You may need to additionally procure data resources (e.g. see the README for more information). Some packages (i.e. `nltk`, `demoji`) may require additional downloads that will be prompted upon the first import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard Library\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from pprint import PrettyPrinter\n",
    "\n",
    "## External Libraries\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Local Module\n",
    "from mhlib.util.logging import initialize_logger\n",
    "from mhlib.preprocess.tokenizer import Tokenizer\n",
    "from mhlib.preprocess.preprocess import tokenizer\n",
    "from mhlib.model import (data_loaders,\n",
    "                         train,\n",
    "                         model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Globals\n",
    "MENTAL_HEALTH_DIR = \"INSERT_ABSOLUTE_PATH_TO_CODE_REPOSITORY_HERE\"\n",
    "LOGGER = initialize_logger()\n",
    "PRINTER = PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "We provide support for interacting with the following datasets from Reddit and Twitter. Please note that appropriate data usage agreements are required to access the data. You will also need to be added to the \"ouat\" security group on the CLSP grid. Besides each official dataset name is the reference name used throughout the `mhlib` codebase. Any datasets not listed below, but housed in the mental health data repository, require additional credentials.\n",
    "\n",
    "### Twitter\n",
    "\n",
    "1. **CLPsych 2015 Shared Task** [*clpsych*, *clpysch_deduped*]: Annotated via self-disclosure + manual annotation. 844 users (control group is age and gender matched). Other disorders: PTSD.\n",
    "2. **Multi-Task Learning** [*multitask*]: Annotated via self-disclosure + manual annotation. 2800 users (control group is age and gender matched). Other disorders: anxiety, depression, suicide attempt, suicidal ideation, eating disorder, panic disorder, schizophrenia, borderline personality disorder, bipolar disorder, PTSD.\n",
    "3. **(1)** and **(2)** combined [*merged*] - Includes all users in the CLPsych 2015 shared task dataset and Multi-Task Learning dataset, accounting for users duplicated across datasets.\n",
    "\n",
    "### Reddit\n",
    "\n",
    "1. **Topic Restricted Text** [*wolohan*]: Individuals who submitted original post in r/Depression labeled as depressed. Individuals who submitted original post in r/AskReddit labeled as control (as long as they weren't already in the depression sample). 7016 control and 6853 depression.\n",
    "2. **RSDD** [*rsdd*]: Annotated via self-disclosures + manual annotation. 107,274 control and 9,210 depression.\n",
    "3. **SMHD** [*smhd*]: Annotated via self-disclosures + manual annotation. 279,561 control and 7,847 depression. Contains users from RSDD. Other disorders: ADHD, anxiety, autism, bipolar disorder, OCD, PTSD, schizophrenia, eating disorders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## View Raw Data Locations\n",
    "raw_data_dirs = [f\"{MENTAL_HEALTH_DIR}data/raw/twitter/\",f\"{MENTAL_HEALTH_DIR}data/raw/reddit/\"]\n",
    "for r in raw_data_dirs:\n",
    "    LOGGER.info(\"\\n\".join([i for i in glob(f\"{r}*/\") if os.path.isdir(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Labels for a Dataset\n",
    "clpsych_labels = train.load_dataset_metadata(\"clpsych\",\n",
    "                                             \"depression\",\n",
    "                                             random_state=42)\n",
    "\n",
    "## Show Distribution\n",
    "LOGGER.info(\"Class Distribution\")\n",
    "for lbl, count in clpsych_labels[\"depression\"].value_counts().items():\n",
    "    LOGGER.info(f\"\\t* {lbl}: {count}\")\n",
    "\n",
    "## Show Sample Labels\n",
    "clpsych_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optionally, Resample Dataset Balance\n",
    "clpsych_labels_rebalanced = train._rebalance(clpsych_labels,\n",
    "                                              \"depression\",\n",
    "                                              target_class_ratio=[1, 5],\n",
    "                                              random_seed=42)\n",
    "LOGGER.info(\"Rebalanced Class Distribution\")\n",
    "for lbl, count in clpsych_labels_rebalanced[\"depression\"].value_counts().items():\n",
    "    LOGGER.info(f\"\\t* {lbl}: {count}\")\n",
    "\n",
    "## Optionally, Downsample Dataset\n",
    "clpsych_labels_downsampled = train._downsample(clpsych_labels,\n",
    "                                               downsample_size=100,\n",
    "                                               random_seed=42)\n",
    "LOGGER.info(\"Downsampled Class Distribution\")\n",
    "for lbl, count in clpsych_labels_downsampled[\"depression\"].value_counts().items():\n",
    "    LOGGER.info(f\"\\t* {lbl}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processed Data\n",
    "\n",
    "Raw datasets have been pre-processed and stored in a consistent format (list of json dictionaries). When possible, pre-processed Reddit data structures include the subreddit the post comes from. If you wish to see how these files were generated, please examine `scripts/preprocess/` for thorough instructions.\n",
    "\n",
    "We provide a helper class, `LoadProcessedData` to load the preprocessed data files and apply additional layers of preprocessing if desired (e.g. filtering out negation tokens or emojis, excluding posts containing certain terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Data Loader for Preprocessed Data\n",
    "loader = data_loaders.LoadProcessedData(filter_negate=True,\n",
    "                                        filter_upper=True,\n",
    "                                        filter_punctuation=False,\n",
    "                                        filter_numeric=True,\n",
    "                                        filter_user_mentions=True,\n",
    "                                        filter_url=True,\n",
    "                                        filter_retweet=True,\n",
    "                                        filter_stopwords=False,\n",
    "                                        keep_pronouns=True,\n",
    "                                        preserve_case=False,\n",
    "                                        filter_empty=True,\n",
    "                                        emoji_handling=None,\n",
    "                                        strip_hashtag=False,\n",
    "                                        max_tokens_per_document=None,\n",
    "                                        max_documents_per_user=10,\n",
    "                                        filter_mh_subreddits=None,\n",
    "                                        filter_mh_terms=\"smhd\",\n",
    "                                        keep_retweets=True,\n",
    "                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Pre-Processed Data\n",
    "sample_file = os.path.abspath(clpsych_labels.iloc[0][\"source\"])\n",
    "LOGGER.info(f\"Loading File: {sample_file}\\n\\n\")\n",
    "user_data = loader.load_user_data(sample_file,\n",
    "                                  min_date=datetime(2013, 1, 1),\n",
    "                                  max_date=datetime(2013, 12, 1),\n",
    "                                  n_samples=20,\n",
    "                                  randomized=True)\n",
    "LOGGER.info(\"Post 1 of {}:\\n\".format(len(user_data)))\n",
    "LOGGER.info(PRINTER.pformat(user_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re-tokenizing Using Standard Tokenizer\n",
    "text = user_data[0].get(\"text\")\n",
    "tokens = tokenizer.tokenize(text)\n",
    "LOGGER.info(\"{}:\\n\\n{}\".format(text, tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re-tokenizing With Non-default Tokenizer Parameters\n",
    "new_tokenizer = Tokenizer(stopwords=[\"else\",\"this\",\"for\"],\n",
    "                          keep_case=False,\n",
    "                          negate_handling=True,\n",
    "                          negate_token=False,\n",
    "                          upper_flag=False,\n",
    "                          keep_punctuation=False,\n",
    "                          keep_numbers=False,\n",
    "                          expand_contractions=True,\n",
    "                          keep_user_mentions=False,\n",
    "                          keep_pronouns=True,\n",
    "                          keep_url=True,\n",
    "                          keep_hashtags=False,\n",
    "                          keep_retweets=False,\n",
    "                          emoji_handling=None,\n",
    "                          strip_hashtag=True)\n",
    "new_tokens = new_tokenizer.tokenize(text)\n",
    "LOGGER.info(new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Our model infrastructure currently supports a classical infrastructure of 1) construct hand-crafted features from a bag-of-words representation of a user's documents and then 2) feed this representation into an estimator (e.g. Logistic Regression). We have abstracted much of the process into a single class, `MentalHealthClassifier`. \n",
    "\n",
    "This instance should be initialized with parameters that control vocabulary construction, feature selection, preprocessing, and model fitting procedures. Optionally, models can be fit with a parallelized grid search procedure that cycles through chosen hyperparameters. Ongoing work looks to incorporate unsupervised domain-adaptation methods (e.g. importance weighting, feature subspace mapping), though their effectiveness is still yet to be proven.\n",
    "\n",
    "To see a comprehensive set of examples of how this class is used, please examine code in `scripts/model/` and `scripts/experiment/`. Note that many of these scripts ingest configurations set in the `configurations/` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct Train/Test Splits\n",
    "np.random.seed(42)\n",
    "train_ind = np.random.choice(clpsych_labels.index,\n",
    "                             int(clpsych_labels.shape[0]*.8),\n",
    "                             replace=False)\n",
    "train_labels = clpsych_labels.loc[train_ind].set_index(\"source\")[\"depression\"].to_dict()\n",
    "target_labels = clpsych_labels.loc[~clpsych_labels.index.isin(train_ind)].set_index(\"source\")[\"depression\"].to_dict()\n",
    "\n",
    "## Distributions\n",
    "train_dist = pd.Series(train_labels).value_counts()\n",
    "target_dist = pd.Series(target_labels).value_counts()\n",
    "LOGGER.info(\"Training Distribution:\\n{}\".format(PRINTER.pformat(train_dist)))\n",
    "LOGGER.info(\"\\nTarget Distribution:\\n{}\".format(PRINTER.pformat(target_dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize MentalHealthClassifier Class\n",
    "mhmod = model.MentalHealthClassifier(target_disorder=\"depression\",\n",
    "                                     model=\"logistic\",\n",
    "                                     model_kwargs={\"C\":100,\n",
    "                                                   \"solver\":\"lbfgs\",\n",
    "                                                   \"max_iter\":1000\n",
    "                                                  },\n",
    "                                     vocab_kwargs={\n",
    "                                                     'filter_negate': False,\n",
    "                                                     'filter_upper': False,\n",
    "                                                     'filter_punctuation': False,\n",
    "                                                     'filter_numeric': False,\n",
    "                                                     'filter_user_mentions': False,\n",
    "                                                     'filter_url': False,\n",
    "                                                     'filter_retweet': False,\n",
    "                                                     'filter_stopwords': False,\n",
    "                                                     'keep_pronouns': True,\n",
    "                                                     'preserve_case': False,\n",
    "                                                     'emoji_handling': None,\n",
    "                                                     'filter_hashtag': False,\n",
    "                                                     'strip_hashtag': False,\n",
    "                                                     'max_vocab_size': 100000,\n",
    "                                                     'min_token_freq': 10,\n",
    "                                                     'max_token_freq': None,\n",
    "                                                     'ngrams': (1, 1),\n",
    "                                                     'max_tokens_per_document': None,\n",
    "                                                     'max_documents_per_user': None,\n",
    "                                                     'binarize_counter': True,\n",
    "                                                     'filter_mh_subreddits': None,\n",
    "                                                     'filter_mh_terms': None,\n",
    "                                                     'keep_retweets': True,\n",
    "                                                     'external_vocab': [],\n",
    "                                                     'external_only': False,\n",
    "                                                     'random_state': 42},\n",
    "                                        preprocessing_kwargs={\n",
    "                                                     'feature_flags':{\n",
    "                                                         \"tfidf\":True,\n",
    "                                                         \"liwc\":True,\n",
    "                                                         \"glove\":False,\n",
    "                                                         \"lda\":False\n",
    "                                                     },\n",
    "                                                     'feature_kwargs':{\n",
    "                                                          \"tfidf\":{\n",
    "                                                              \"norm\":\"l2\"\n",
    "                                                          },\n",
    "                                                         \"liwc\":{\n",
    "                                                             \"norm\":\"matched\"\n",
    "                                                         },\n",
    "                                                         \"glove\":{\n",
    "                                                             \"dim\":200\n",
    "                                                         },\n",
    "                                                         \"lda\":{\n",
    "                                                             \"n_components\":30\n",
    "                                                         }\n",
    "                                                     }\n",
    "                                            },\n",
    "                                        feature_selector=\"pmi\",\n",
    "                                        feature_selection_kwargs={\n",
    "                                                                \"min_support\":10,\n",
    "                                                                \"top_k\":10000\n",
    "                                            },\n",
    "                                        min_date=\"2011-01-01\",\n",
    "                                        max_date=\"2013-12-01\",\n",
    "                                        randomized=False,\n",
    "                                        vocab_chunksize=50,\n",
    "                                        jobs=4,\n",
    "                                        random_state=42,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit Model\n",
    "mhmod, train_preds = mhmod.fit(train_files=sorted(train_labels.keys()),\n",
    "                               label_dict=train_labels,\n",
    "                               return_training_preds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Test Predictions\n",
    "test_preds = mhmod.predict(sorted(target_labels.keys()),\n",
    "                           min_date=None,\n",
    "                           max_date=None,\n",
    "                           n_samples=None,\n",
    "                           randomized=False,\n",
    "                           drop_null=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Isolate Non-null Samples\n",
    "train_nn = [t for t in train_labels if t in train_preds]\n",
    "target_nn = [t for t in target_labels if t in test_preds]\n",
    "\n",
    "## Format Predictions + Ground Truth\n",
    "y_train_true = [int(train_labels[f]!=\"control\") for f in sorted(train_nn)]\n",
    "y_train_pred = [train_preds[f] for f in sorted(train_nn)]\n",
    "y_test_true = [int(target_labels[f]!=\"control\") for f in sorted(target_nn)]\n",
    "y_test_pred = [test_preds[f] for f in sorted(target_nn)]\n",
    "\n",
    "\n",
    "## Plot Class Separation\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,5.8))\n",
    "for g, (group, group_true, group_pred) in enumerate(zip([\"Training\",\"Test\"],\n",
    "                                              [y_train_true,y_test_true],\n",
    "                                              [y_train_pred,y_test_pred])):\n",
    "    yt = np.array(group_true)\n",
    "    yp = np.array(group_pred)\n",
    "    auc = metrics.roc_auc_score(yt, yp)\n",
    "    for lbl in [0, 1]:\n",
    "        ax[g].hist(yp[yt==lbl],\n",
    "                   color=f\"C{lbl}\",\n",
    "                   bins=np.linspace(0,1,21),\n",
    "                   alpha=0.5,\n",
    "                   label=\"Control\" if lbl == 0 else \"Depression\")\n",
    "    ax[g].set_xlabel(\"Probability\")\n",
    "    ax[g].legend(loc=\"best\",title=\"True Label\")\n",
    "    ax[g].set_ylabel(\"Sample Frequency\")\n",
    "    ax[g].set_title(\"{} AUC={:.3f}\".format(group, auc), loc=\"left\", fontweight=\"bold\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract Feature Coefficients\n",
    "coefs_ = pd.Series(index=mhmod.get_feature_names(),\n",
    "                   data=mhmod.model.coef_[0])\n",
    "top_coefs_ = coefs_.nlargest(20).append(coefs_.nsmallest(20)).sort_values()\n",
    "\n",
    "## Look at Top Coefficients\n",
    "fig, ax = plt.subplots(figsize=(10,5.8))\n",
    "_ = top_coefs_.plot.barh(ax=ax, color=\"C0\", alpha=.8)\n",
    "_ = ax.axvline(0, color=\"black\", linestyle=\"--\", alpha=.8)\n",
    "_ = ax.set_xlabel(\"Coefficient\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at Results of Feature Selection Procedure\n",
    "selector = mhmod.selector._selector\n",
    "pmi = selector.get_pmi().sort_values(1, ascending=False)\n",
    "pmi.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Model\n",
    "LOGGER.info(\"Caching Model\")\n",
    "_ = mhmod.dump(\"clpsych.model.joblib\",\n",
    "               compress=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a Cached Model\n",
    "cached_model = joblib.load(\"clpsych.model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
